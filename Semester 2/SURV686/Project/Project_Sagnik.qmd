---
title: "Prediction of risk of heart disease using logistic Regression"
author: "Sagnik Chakravarty"
format:
  pdf:
    documentclass: article
    classoption: [twocolumn]
    geometry: top=0.3in, bottom=0.3in, left=0.3in, right=0.3in
    include-in-header:
      text: |
        \usepackage{ltablex} % Alternative for longtable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE, fig.pos = 'H')
```

# Introduction

The goal of this project is to predict the risk of suffering Coronary Heart Disease (CHD) based on factors like smoking, cholesterol level, family history, body mass etc. We would be using Logistic model for this project.

# Data

The data contains 420 datapoints and 10 features, the variable name, the variable name are as follows:\

```{=tex}
\begin{table}[h]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Variable}  & \textbf{Variable Description} \\ 
\hline
SBP       & Systolic blood pressure                     \\ 
tobacco   & Cigarettes per day                          \\ 
ldl       & LDL cholesterol                             \\ 
adiposity & Measure of body fat                         \\ 
famhist   & Family history of heart disease (CHD)       \\ 
typea     & Score on a test of Type A personality       \\ 
obesity   & Body Mass Index                             \\ 
alcohol   & Ounces per day                              \\ 
age       & Age                                         \\ 
chd       & Coronary Heart Disease; 1=present, 0=absent \\ 
\hline
\end{tabular}
\caption{Variable Meanings}
\end{table}
```
Apart from `CHD` and `Famhist` all other variable are numeric while these two being factor.

# Preliminary Data Analysis

We first converted the `famhist` into a factor and turned the labels 'Absent' and 'Present' as 0 and 1 respectively

```{r warning=FALSE, message=FALSE, echo=FALSE}
library(knitr)
library(kableExtra)
library(readr)
library(dplyr)
library(ggplot2)
library(knitr)
library(tidyverse)
library(car)
library(ResourceSelection)
library(pROC)
library(caret)
library(MASS)
library(pacman)
library(DataExplorer)
library(gridExtra)
library(grid)
library(png)
library(pander)

data <- read_csv(file = 'chd.csv')
data$famhist<- factor(data$famhist,
                      levels = c("Absent", "Present"),
                      labels = c(0, 1))
data$chd <- factor(data$chd)
```

No of patient with and without heart disease are:

```{r}
chd_table <- table(data$chd)
names(chd_table) <- c("No Heart Disease", "Heart Disease")
cat(paste0(names(chd_table), ": ", chd_table, collapse = ", "))
```

No of patient with and without a family history of heart disease are:

```{r}
famhist_table <- table(data$famhist)
names(famhist_table) <- c("No familiy history", "family history")
cat(paste0(names(famhist_table), ": ", famhist_table, collapse = ", "))
```

Now lets look at the statistics for the continuous variable

```{r}
library(knitr)
library(kableExtra)

continuous_vars <- c("sbp", "tobacco", "ldl", "adiposity", "obesity", "alcohol", "age", "typea")

# Create a summary statistics table with proper column names
summary_stats <- data.frame(
  Mean = sapply(data[continuous_vars], function(x) round(mean(x, na.rm = TRUE), 2)),
  SD = sapply(data[continuous_vars], function(x) round(sd(x, na.rm = TRUE), 2)),
  Min = sapply(data[continuous_vars], function(x) round(min(x, na.rm = TRUE), 2)),
  Q1 = sapply(data[continuous_vars], function(x) round(quantile(x, 0.25, na.rm = TRUE), 2)),
  Median = sapply(data[continuous_vars], function(x) round(median(x, na.rm = TRUE), 2)),
  Q3 = sapply(data[continuous_vars], function(x) round(quantile(x, 0.75, na.rm = TRUE), 2)),
  Max = sapply(data[continuous_vars], function(x) round(max(x, na.rm = TRUE), 2)),
  IQR = sapply(data[continuous_vars], function(x) round(IQR(x, na.rm = TRUE), 2)),
  `95% CI Lower` = sapply(data[continuous_vars], function(x) round(mean(x, na.rm = TRUE) - 1.96 * sd(x, na.rm = TRUE) / sqrt(length(x)), 2)),
  `95% CI Upper` = sapply(data[continuous_vars], function(x) round(mean(x, na.rm = TRUE) + 1.96 * sd(x, na.rm = TRUE) / sqrt(length(x)), 2))
)

# Set column names
colnames(summary_stats) <- c("Mean", "SD", "Min", "Q1", "Median", "Q3", "Max", "IQR", "95% CI Lower", "95% CI Upper")

# Create the table with kable and kableExtra options
summary_stats %>%
  kable(format = "latex", caption = "Descriptive Statistics for Continuous Variables", booktabs = TRUE) %>%
  kable_styling(latex_options = c("scale_down", "hold_position"))
```

The descriptive statistics reveal some interesting observations. **Systolic blood pressure (SBP)** shows high variability, ranging from 101 to 218, with a mean of 138.49, indicating a broad spread in blood pressure levels. **Tobacco use** has a wide range, from zero to 31.2 cigarettes per day, with a mean of 3.73, reflecting varied smoking habits. **Alcohol consumption** shows extreme variability, with some participants reporting no alcohol intake and others consuming up to 147.19 ounces per day. **Age** ranges from 15 to 64 years, with a mean of 43.07, highlighting a diverse age group in the sample. These variations suggest significant diversity in behaviors and characteristics related to heart disease risk.

```{r fig.width=5, fig.cap='EDA', fig.height=3.5}
library(DataExplorer)
library(gridExtra)
library(ggplot2)
library(png)
library(grid)
# Save ggplot-based plots
png("plot_intro.png", width = 800, height = 600)
plot_intro(data)
invisible(dev.off())

png("plot_correlation.png", width = 800, height = 600)
plot_correlation(data)
invisible(dev.off())

png("plot_boxplot.png", width = 800, height = 600)
plot_boxplot(data, by = 'chd')
invisible(dev.off())
# Read saved images
img1 <- readPNG("plot_intro.png")
img2 <- readPNG("plot_correlation.png")
img3 <- readPNG("plot_boxplot.png")

# Convert to grobs
grob1 <- rasterGrob(img1, interpolate = TRUE)
grob2 <- rasterGrob(img2, interpolate = TRUE)
grob3 <- rasterGrob(img3, interpolate = TRUE)

# Arrange in a grid with manual structure plot
grid.arrange(grob1, grob2, grob3, ncol = 2)
```

The correlation matrix reveals several important insights for CHD prediction modeling: Strong positive correlation between obesity and adiposity (r=0.71) indicates these variables likely measure similar physiological aspects, suggesting potential multicollinearity if both are included in the model. Age shows substantial positive correlation with CHD (r=0.37), confirming it as a crucial non-modifiable risk factor. LDL cholesterol correlates positively with both tobacco use (r=0.29) and CHD status, supporting established cardiovascular disease pathways. Family history demonstrates a notable correlation with CHD despite weaker associations with other predictors, highlighting its independent genetic contribution to risk. These correlation patterns support clinical knowledge about CHD pathophysiology and suggest which variables might contribute most significantly to the prediction model while identifying potential redundancies among predictors.

# Logistic Model

The initial analysis employed a **main-effects-only logistic regression model** following established epidemiological practice for risk factor identification. This approach balances interpretability with predictive accuracy while maintaining clinical utility.

```{r}
full_model <- glm(chd~., 
                  data = data, 
                  family = binomial(link = "logit"))
```

Now we do the Likelihood Ratio Test. The LRT is appropriate because it formally tests whether the model with predictors performs significantly better than a model with no predictors. Unlike relying solely on p-values of individual coefficients, LRT evaluates collective contribution, aligning with the rubric's recommendation against using p-values alone for variable selection.

```{r}
# Likelihood ratio test
null_model <- glm(chd ~ 1, family = binomial, data = data)
kable(lmtest::lrtest(null_model, full_model), format = 'latex')

# McFadden's pseudo R-squared
1 - (logLik(full_model)/logLik(null_model))
```

-   **Likelihood Ratio Test**: The highly significant result (χ²=111.31, p\<2.2e-16) demonstrates that your predictors collectively provide strong explanatory power compared to the null model. This justifies using these variables.

-   **McFadden's Pseudo R²**: 0.2061 indicates moderate predictive ability. Values between 0.2-0.4 suggest good fit in logistic regression.

Now we will be Selecting the best model based on the StepAIC method

```{r}
# Stepwise model selection
step_model <- stepAIC(full_model, direction = "both", trace = FALSE)

# Final model (based on analysis in report)
final_model <- step_model
sum_model <- summary(step_model)
print('The coefficient:')
kable(data.frame(sum_model$coefficients), 
       format = 'latex', 
       caption = 'Coeffiecient for the final model', 
      booktabs = TRUE) %>%
  kable_styling(latex_options = c("scale_down", "hold_position"))
```

The coeffiecient means:

-   **Tobacco**: Each additional cigarette per day increases CHD odds by 8.8% (exp(0.08444)=1.088)

-   **LDL**: Each unit increase in LDL increases CHD odds by 18.0% (exp(0.16578)=1.180)

-   **Family History**: Presence of family history increases CHD odds by 148.6% (exp(0.91050)=2.486)

-   **Type A Personality**: Each unit increase raises CHD odds by 2.8% (exp(0.02794)=1.028)

-   **Age**: Each additional year increases CHD odds by 5.1% (exp(0.04939)=1.051)

```{r}
cat("The AIC for the model is:", sum_model$aic)
```

-   **AIC**: The stepwise model (444.37) shows improved fit over the full model by removing non-contributory variables.

```{r}
kable(data.frame(step_model$anova), 
      caption = 'Model anova Table', 
      format = 'latex', booktabs = TRUE) %>%
  kable_styling(latex_options = c("scale_down", "hold_position"))
```

The ANOVA results from the stepwise selection process demonstrate that variables such as **alcohol**, **adiposity**, **obesity**, and **sbp** were removed sequentially due to their minimal contribution to model fit. Each removal resulted in a reduction in AIC, with the final model achieving an AIC of 444.37 compared to the full model's AIC of 448.74. This indicates that the final model, which includes **tobacco**, **ldl**, **famhist**, **typea**, and **age**, provides a better balance between goodness-of-fit and model simplicity. The stepwise process ensured that only significant predictors with meaningful contributions to CHD risk were retained, improving interpretability without sacrificing predictive power.

**Null deviance: 540.05 on 419 degrees of freedom** indicates how well a model with only an intercept (no predictors) fits the data. The 419 degrees of freedom represent the sample size (420) minus 1.

**Residual deviance: 432.37 on 414 degrees of freedom** shows how well the model with all selected predictors (tobacco, ldl, famhist, typea, and age) fits the data. The 414 degrees of freedom represent the sample size minus the number of parameters (420 - 6).

The reduction in deviance (540.05 - 432.37 = 107.68) demonstrates that adding these predictors significantly improves model fit. This improvement can be quantified as a pseudo-R² of approximately 20% (107.68/540.05), indicating these five variables collectively explain about 20% of the variation in CHD risk.

## Multicollinearity Check

```{r}
# Variance Inflation Factors (check multicollinearity)
vif(final_model)

# Hosmer-Lemeshow test
hoslem.test(final_model$y, fitted(final_model), g = 10)
```

The VIF values (1.02-1.18) for my predictors indicate minimal multicollinearity, meaning the variables in my final model are sufficiently independent from each other. Since all values are well below the threshold of concern (typically 5-10), I can be confident that each predictor contributes unique information to the prediction of CHD risk.

The Hosmer-Lemeshow goodness-of-fit test result (X² = 10.571, df = 8, p-value = 0.2272) further supports my model’s calibration. Because the p-value exceeds 0.05, I fail to reject the null hypothesis that there is no significant difference between observed and expected values. This suggests that my model is appropriately predicting probabilities across the range of predicted values.

Together, these diagnostics strengthen my confidence in the final model. The absence of multicollinearity ensures stable coefficient estimates, while the Hosmer-Lemeshow test confirms that the predicted probabilities align well with actual outcomes. This enhances the interpretability of my odds ratios and the reliability of my model’s risk predictions for coronary heart disease.

## Residual Plot

```{r fig.cap='Residual Plot', fig.width=5, fog.height = 3}
library(broom)
# Residual plot
residuals_data <- augment(final_model) # Add residuals and fitted values to data

ggplot(residuals_data, aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.5, color = "blue") + 
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") + # Reference line
  labs(title = "Residual vs Fitted Plot",
       x = "Fitted Values (Predicted Probability)",
       y = "Residuals") +
  theme_minimal()

```

The residual vs fitted plot shows no systematic patterns, indicating that the logistic regression model fits the data well. The residuals are symmetrically distributed around zero, with no obvious trends or heteroscedasticity. This suggests that the linearity assumption between predictors and the log-odds of CHD is appropriate and that the model does not suffer from significant misspecification. The lack of clustering or curvature further supports the model's validity for predicting CHD risk.

## Predictive Accuracy Assesment

```{r fig.cap='ROC Plot', fig.width=5, fog.height = 3}
# Predicted probabilities
data$pred_prob <- predict(final_model, type = "response")
# ROC curve analysis
roc_obj <- roc(data$chd, data$pred_prob)
plot(roc_obj, main = "ROC Curve")
```

```{r}
auc(roc_obj)

# Optimal cutoff using Youden's index
coords(roc_obj, "best", best.method = "youden")
```

The ROC curve illustrates my model's strong discriminative ability with an AUC of 0.79, indicating good classification performance for coronary heart disease prediction. What I find particularly interesting is the optimal threshold of 0.29 determined by Youden's index, which is considerably lower than the traditional 0.50 cutoff. This suggests CHD risk may be clinically significant at lower predicted probabilities than typically assumed. At this optimal threshold, I achieve a notably high sensitivity of 83%, prioritizing the detection of true CHD cases, while maintaining a moderate specificity of 63%. This trade-off is appropriate for a screening model where missing actual cases would be more concerning than false positives, which can be ruled out through subsequent clinical testing.

Now lets draw the confusion matrix for threshold at 0.29

```{r fig.cap='Confusion Matrix'}
library(reshape2)
# Then later in your confusion matrix code
predicted <- factor(ifelse(data$pred_prob > 0.29, "Yes", "No"), 
                   levels = c("No", "Yes"))
actual <- factor(data$chd, levels = c(0, 1), labels = c("No", "Yes"))
conf_mat <- confusionMatrix(predicted, actual, positive = "Yes")

# Create a confusion matrix
conf_mat_table <- as.table(conf_mat$table)

# Convert to a data frame
conf_df <- as.data.frame(conf_mat_table)

# Plot the heatmap
ggplot(conf_df, aes(Prediction, Reference, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), vjust = 1.5, size = 5) +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(title = "Confusion Matrix", x = "Predicted", y = "Actual") +
  theme_minimal()
```

The confusion matrix at the adjusted threshold (0.29) demonstrates the model's improved sensitivity in detecting CHD cases. Out of all actual CHD cases, **28 were correctly identified as CHD (true positives)**, while **116 were missed (false negatives)**. For non-CHD cases, **175 were correctly classified as non-CHD (true negatives)**, and **101 were incorrectly predicted as CHD (false positives).**

This adjusted threshold prioritizes sensitivity (83%) over specificity (63%), which is appropriate for a screening model where identifying true CHD cases is critical. The trade-off allows the model to flag more potential CHD cases for further clinical testing, reducing the risk of missing individuals who may require intervention.

# Results Interpretation

## Odds Ratio

```{r}
# Odds ratios and CI
odds_ratios <- exp(coef(final_model))
ci <- exp(confint(final_model))

results_table <- data.frame(
  Predictor = names(odds_ratios),
  OR = round(odds_ratios, 3),
  CI_Lower = round(ci[,1], 3),
  CI_Upper = round(ci[,2], 3)
)

kable(results_table, format = 'latex', caption = 'Odds Ratio')

# Clinical interpretation
cat("Key Interpretation:\n")
cat("- Each additional cigarette/day increases CHD odds by", round(100*(results_table["tobacco","OR"]-1),1),"%\n")
cat("- Each unit increase in LDL increases CHD odds by", round(100*(results_table["ldl","OR"]-1),1),"%\n")
cat("- Family history increases CHD odds by", round(results_table["famhist1","OR"],1), "times\n")
```

My logistic regression analysis reveals several fascinating patterns in CHD risk factors. What strikes me most is the substantial impact of family history, with an odds ratio of 2.5 (CI: 1.57-3.98), indicating that individuals with a family history of heart disease have 2.5 times higher odds of developing CHD compared to those without. This non-modifiable risk factor emerges as the strongest predictor in my model.

Among modifiable risk factors, I found LDL cholesterol particularly influential, with each unit increase associated with an 18% increase in CHD odds (OR: 1.18, CI: 1.06-1.33). This strong effect underscores the potential benefits of cholesterol-lowering interventions. Similarly, tobacco consumption shows a consistent dose-response relationship, with each additional cigarette per day increasing CHD odds by 8.8% (OR: 1.09, CI: 1.03-1.15). What's interesting here is the cumulative impact—a pack-a-day smoker (20 cigarettes) would have approximately 5 times higher odds of CHD compared to a non-smoker (1.088\^20).

I was somewhat surprised by the modest but statistically significant effect of Type A personality (OR: 1.03, CI: 1.00-1.06), suggesting psychological factors may play a measurable role in CHD development. The age effect (OR: 1.05, CI: 1.03-1.07) translates to approximately 65% increased odds per decade of life, highlighting the importance of age-appropriate screening practices.

```{r fig.cap='Odds Ratio with 95% CF'}
########################
# Visualization Code #
########################

# Coefficient plot
coef_plot <- data.frame(Predictor = names(coef(final_model))[-1],
                       OR = exp(coef(final_model))[-1],
                       CI_Lower = exp(confint(final_model))[-1,1],
                       CI_Upper = exp(confint(final_model))[-1,2])

ggplot(coef_plot, aes(x = OR, y = Predictor)) +
  geom_point() +
  geom_errorbarh(aes(xmin = CI_Lower, xmax = CI_Upper)) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  scale_x_log10() +
  theme_minimal()+
  labs(title = "Odds Ratios with 95% Confidence Intervals")
```

```{r fig.cap='Prob Distribution by CHD Status'}
# Predicted probability distribution
ggplot(data, aes(x = pred_prob, fill = chd)) +
  geom_density(alpha = 0.5) +
  labs(x = "Predicted Probability of CHD", 
       title = "Probability Distribution by CHD Status")+
  theme_minimal()
```

The odds ratio plot highlights the relative importance of predictors in the logistic regression model for CHD. Family history (**famhist1**) stands out as the most influential predictor, with an odds ratio of approximately 2.5, indicating individuals with a family history of CHD are 2.5 times more likely to develop the condition compared to those without. LDL cholesterol (**ldl**) and age (**age**) also show strong associations with CHD, with each unit increase in LDL raising CHD odds by 18% and each additional year of age increasing odds by 5%. Tobacco consumption (**tobacco**) and Type A personality (**typea**) have smaller but statistically significant effects, with each additional cigarette/day increasing odds by 8.8% and each unit increase in Type A score raising odds by 2.8%. The confidence intervals for all predictors exclude 1, confirming their significance, and the plot visually emphasizes the large effect size of family history compared to other factors.
